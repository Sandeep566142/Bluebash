{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61e442-94ce-463c-b56c-04ee3b743500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "file_path = 'smallest training.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Dropping unimportant columns\n",
    "columns_to_drop = ['beer/beerId', 'beer/brewerId', 'review/timeStruct', 'review/timeUnix',\n",
    "                   'user/ageInSeconds', 'user/birthdayRaw', 'user/birthdayUnix',\n",
    "                   'user/gender', 'user/profileName', 'index']\n",
    "\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "X = data.drop(columns='review/overall', axis=1)\n",
    "Y= data['review/overall']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Loading the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function for preprocessing the text using Spacy\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_punct and not token.is_stop]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Loading pre-trained BERT tokenizer and model from Hugging face library\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function for tokenizing and converting texts to BERT embeddings\n",
    "def tokenize_and_vectorize(text):\n",
    "    tokens = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='tf', padding=True, truncation=True)\n",
    "    outputs = model(tokens)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()\n",
    "\n",
    "# Applying BERT tokenization and vectorization to the columns having text data in both training and testing datasets\n",
    "text_columns= ['beer/name','beer/style','review/text']\n",
    "# Initializing lists for each column\n",
    "all_texts_name = []\n",
    "all_texts_style = []\n",
    "all_texts_review = []\n",
    "\n",
    "# preprocessing each text in the cells of each of the text_columns using spacy\n",
    "for item in text_columns:\n",
    "    if item == 'beer/name':\n",
    "        all_texts_name.extend(preprocess_text(text) for text in X_train[item].astype(str))\n",
    "    elif item == 'beer/style':\n",
    "        all_texts_style.extend(preprocess_text(text) for text in X_train[item].astype(str))\n",
    "    elif item == 'review/text':\n",
    "        all_texts_review.extend(preprocess_text(text) for text in X_train[item].astype(str))\n",
    "\n",
    "# Tokenizing and vectorizing using BERT \n",
    "X_train_bert_name = np.array([tokenize_and_vectorize(text) for text in all_texts_name])\n",
    "X_train_bert_style = np.array([tokenize_and_vectorize(text) for text in all_texts_style])\n",
    "X_train_bert_review = np.array([tokenize_and_vectorize(text) for text in all_texts_review])\n",
    "\n",
    "# Doing the same process for the test dataset\n",
    "all_texts_name_test = []\n",
    "all_texts_style_test = []\n",
    "all_texts_review_test = []\n",
    "\n",
    "for item in text_columns:\n",
    "    if item == 'beer/name':\n",
    "        all_texts_name_test.extend(preprocess_text(text) for text in X_test[item].astype(str))\n",
    "    elif item == 'beer/style':\n",
    "        all_texts_style_test.extend(preprocess_text(text) for text in X_test[item].astype(str))\n",
    "    elif item == 'review/text':\n",
    "        all_texts_review_test.extend(preprocess_text(text) for text in X_test[item].astype(str))\n",
    "\n",
    "X_test_bert_name = np.array([tokenize_and_vectorize(text) for text in all_texts_name_test])\n",
    "X_test_bert_style = np.array([tokenize_and_vectorize(text) for text in all_texts_style_test])\n",
    "X_test_bert_review = np.array([tokenize_and_vectorize(text) for text in all_texts_review_test])\n",
    "\n",
    "\n",
    "# Flattening the BERT embeddings\n",
    "X_train_bert_name_flat = X_train_bert_name.reshape(X_train_bert_name.shape[0], -1)\n",
    "X_train_bert_style_flat = X_train_bert_style.reshape(X_train_bert_style.shape[0], -1)\n",
    "X_train_bert_review_flat = X_train_bert_review.reshape(X_train_bert_review.shape[0], -1)\n",
    "\n",
    "X_test_bert_name_flat = X_test_bert_name.reshape(X_test_bert_name.shape[0], -1)\n",
    "X_test_bert_style_flat = X_test_bert_style.reshape(X_test_bert_style.shape[0], -1)\n",
    "X_test_bert_review_flat = X_test_bert_review.reshape(X_test_bert_review.shape[0], -1)\n",
    "\n",
    "\n",
    "#numerical features from X_train\n",
    "dx_train=X_train.drop(columns=text_columns,axis=1)\n",
    "dx_test=X_test.drop(columns=text_columns,axis=1)\n",
    "\n",
    "# Concatenating BERT embeddings with the remaining numerical features of X_train\n",
    "X_train_combined = np.concatenate([X_train_bert_name_flat,X_train_bert_style_flat,X_train_bert_review_flat, dx_train.values], axis=1)\n",
    "X_test_combined = np.concatenate([X_test_bert_name_flat,X_test_bert_style_flat,X_test_bert_review_flat,dx_test.values], axis=1)\n",
    "\n",
    "# Defining the parameter grid for Random Forest Regressor\n",
    "param_grid_rf = {\n",
    "    'randomforestregressor__n_estimators': [50, 100, 150],\n",
    "    'randomforestregressor__max_depth': [None, 10, 20],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "# Defining the parameter grid for Support Vector Regressor\n",
    "param_grid_svr = {\n",
    "    'svr__C': [0.1, 1, 10],\n",
    "    'svr__epsilon': [0.1, 0.2, 0.5],\n",
    "    'svr__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Creating a pipeline for Random Forest Regressor\n",
    "rf_pipe = make_pipeline(RandomForestRegressor(random_state=42))\n",
    "\n",
    "# Creating a pipeline for Support Vector Regressor with standardization\n",
    "svr_pipe = make_pipeline(StandardScaler(), SVR())\n",
    "\n",
    "# Creating GridSearchCV objects for both models\n",
    "grid_search_rf = GridSearchCV(rf_pipe, param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_svr = GridSearchCV(svr_pipe, param_grid_svr, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the models with grid search\n",
    "grid_search_rf.fit(X_train_combined, y_train)\n",
    "grid_search_svr.fit(X_train_combined, y_train)\n",
    "\n",
    "# Retreiving the best models\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "best_model_svr = grid_search_svr.best_estimator_\n",
    "\n",
    "# Making predictions on the test set using the best models\n",
    "predictions_rf = best_model_rf.predict(X_test_combined)\n",
    "predictions_svr = best_model_svr.predict(X_test_combined)\n",
    "\n",
    "# Model Validation Metrics\n",
    "mse_rf = mean_squared_error(y_test, predictions_rf)\n",
    "mae_rf=mean_absolute_error(y_test,predictions_rf)\n",
    "r2_rf = r2_score(y_test, predictions_rf)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, predictions_svr)\n",
    "mae_rf=mean_absolute_error(y_test,predictions_rf)\n",
    "r2_svr = r2_score(y_test, predictions_svr)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor:\")\n",
    "print(f'Best parameters: {grid_search_rf.best_params_}')\n",
    "print(f'Mean Squared Error: {mse_rf}')\n",
    "print(f'Mean Absolute Error: {msae_rf}')\n",
    "print(f'R-squared Score: {r2_rf}')\n",
    "print(\"\\nSupport Vector Regressor:\")\n",
    "print(f'Best parameters: {grid_search_svr.best_params_}')\n",
    "print(f'Mean Squared Error: {mse_svr}')\n",
    "print(f'Mean Absolute Error: {mae_svr}')\n",
    "print(f'R-squared Score: {r2_svr}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
